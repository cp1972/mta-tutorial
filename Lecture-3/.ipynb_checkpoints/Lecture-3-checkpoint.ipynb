{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data driven preprocessing\n",
    "\n",
    "In this lecture, we are showing how you can process your text data, and how you can parse them in order to have the best input for topic modelling. As you will learn, you have automatic ways to do this provided by some low level programming utilities which are -- at least for the major part of them -- natively implemented in the linux ecosystem and, therefore, are available directly out of your usb-stick.\n",
    "\n",
    "Even if these utilities are useful, it is rarely the case that they do all the job for you, so that some handwork might be necessary in case of texts that are difficult to parse. Take these tools as a way to speed up your work on the preprocessing of texts, nothing more (but also nothing less)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "Software for data science like the MTA software that we will use in our lecture mostly work on the basis of simple text files (* .txt data), which are light-weight and which you can modify in several ways. The first challenge that you meet when you get some text data is then to convert them into * .txt data. You can get you data in the following formats: \n",
    "\n",
    "  - **image data and * .pdf image-data**: in this case, you have to ocerise your data by using an ocr which extracts the text out of the data. In the Linux ecosystem, you have a very powerfull tool to do that which is called tesseract-ocr; using your terminal in Linux, you can easily install tesseract and its languages files (for the ocerisation in several languages) with the following command (cf. our lecture 2): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo apt-get install tesseract-ocr tesseract-ocr-all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, you can use tesseract-ocr to ocerise your data -- do pay attention that you need to write a script for tesseract-ocr to work as you would like (beyond of this tutorial), as f.ex. to ocerise texts in several languages at once, or to ocerise texts printed in several columns.\n",
    "\n",
    "  - **sandwich pdf data**: these are a specific case of pdf data which you can extract the text by copy/paste from; I don't recommand this, because you would also copy non visible elements from the pdf data that you would have to hunt down and delete afterwards. Instead, you can use a powerful utility called pdftotext to extract the text out of these data. You can install this software, which is part of the package poppler-utils, using the command line like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo apt-get install poppler-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a sandwich pdf data like SandwichPDF.pdf, and let us convert it into txt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pdftotext SandwichPDF.pdf # will save the data as SandwichPDF.txt\n",
    "# pdftotext SandwichPDF.pdf mytext.txt -- would save the data SandwichPDF.pdf as mytext.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the resulting data, we have made out of this sandwich pdf is a text data without layout -- and I recommand to do it like this, because here we have a text on several columns. If you would like to retain the layout, you could do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pdftotext -layout SandwichPDF.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would get a text data preserving (more or less) the layout of the sandwich pdf -- but you would get problems major difficulties with your analysis. The reason of that is the following. Let us see a sample of the resulting text data with the layout:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "      D     ietrich Bonhoeffer ist umstritten.\n",
    "            Dieses Phänomen zieht sich als roter\n",
    "      Faden durch Leben und Rezeption des\n",
    "                                                      von akademischem, sondern auch von\n",
    "                                                      populärem Interesse.\n",
    "                                                          Dass Rezeption immer auch Deutung\n",
    "      Pfarrers, Theologen und Widerständlers.         im Sinne je eigener Auffassungen bis hin   <---- One line == one sentence\n",
    "      Man kann hier nicht nur an die Entfernung       zur Aneignung bedeuten kann, ist eine\n",
    "      Bonhoeffers aus dem Lehrkörper der Theo-        Binsenweisheit. Der amerikanische The-  <---- Next difficulty: dash to cut lines will remain\n",
    "      logischen Fakultät der Berliner Universität,    ologe Stephen R. Haynes hat in seinem\n",
    "      sondern auch an die problematische Stel-        sehr lesenswerten Buch The Bonhoeffer\n",
    "      lung im Umfeld der Bekennenden Kirche,          Phenomenon. Portraits of a Protestant Saint\n",
    "      die Beurteilung des Widerstands im Kon-         gezeigt, in welchem Maße die globale Re-\n",
    "      text der westdeutschen Nachkriegsgerichts-      zeption Bonhoeffers Elemente klassischer\n",
    "      barkeit, die umstandslose Vereinnahmung         Hagiografien aufnimmt, warum Bonhoef-\n",
    "      im Zusammenhang der offiziellen Theolo-         fers Biografie für diese Art der Deutung\n",
    "      gie der DDR oder den Streit um die liberale     offen ist und welche Chancen und Ge-\n",
    "      und konservative Deutung in den 1980er-         fahren damit verbunden sind. Zentral ist\n",
    "      und 1990er-Jahren des 20. Jahrhunderts          der religiös motivierte, entschiedene, bis\n",
    "      denken.                                         zum Verlust des eigenen Lebens gehende\n",
    "          Auch der Ansatz von Eric Metaxas,           Einsatz für etwas, das als richtig erkannt\n",
    "      der Bonhoeffer als Paradigma des kon-           worden ist und – wie im Fall des Wider-\n",
    "      servativen Evangelikalen zu skizzieren          stands gegen den Nationalsozialismus –\n",
    "      sucht, ist nicht ganz ohne Vorbilder, hat-      auch allgemein als richtig anerkannt wird.\n",
    "      te doch Georg Huntemann schon in den            Bedeutsam ist weiterhin der Kontrast zwi-\n",
    "      1990er-Jahren den „anderen Bonhoeffer“          schen glücklicher Kindheit, erfolgreicher\n",
    "      verkündet.                                      Jugend und dem konsequenten Dasein als\n",
    "          Was also ist neu an der Diskussion,         Märtyrer und Zeuge. Zentral ist aber auch\n",
    "      wer war er wirklich, und was lässt sich von     die Fragmentarität und damit Interpreta-\n",
    "      ihm für die Gegenwart lernen? Um diese          tionsoffenheit des hinterlassenen Werks.\n",
    "      Fragen beantworten zu können, lohnt –               Die Chance solcher Deutung liegt in\n",
    "      gerade angesichts des 75. Jahrestags seiner     der religiösen und moralischen Orientie-\n",
    "      staatlich angeordneten Ermordung – ein          rungsfunktion, die – weit über den akade-\n",
    "      Blick auf die Eigenart gegenwärtiger Bon-       mischen Kontext hinaus – gesellschaftlich\n",
    "      hoeffer-Rezeption und zentrale Aspekte\n",
    "      seiner theologischen Biografie.                         Gefängniszelle in Berlin-Tegel,\n",
    "          1. Der „protestantische Heilige“ und sei-      in der Bonhoeffer von 1943 bis 1944\n",
    "      ne gegenwärtige Rezeption: Es ist nicht zu                              inhaftiert war.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass this text to a learning programm, this programm will read the data line by line, and it will interprete these lines as sentences on which it will compute a model for you. This is clearly something that we don't want here, because we would have sentences which do not reflect the content of our text. Therefore, do not use the layout option of pdftotext. \n",
    "\n",
    "We know how to deal with pdf data as image or as sandwich pdf. But we have other types of data, as for example: \n",
    "\n",
    "  - **doc(x)** data;\n",
    "  - **rtf** data;\n",
    "  - **odt(s)** data;\n",
    "  - **htm(l)** data;\n",
    "  - **x(h)tml** data.\n",
    "  \n",
    "In order to convert such data, we can use the LibreOffice --headless flag, like this at the example of the CP-Abstracts.doc data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!soffice --headless --convert-to txt:Text CP-Abstracts.doc  #<-- replace .doc with .rtf or .odt or .html etc for corresponding files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these utilities, you can easily achieve the conversion of a lot of different formats into the * .txt format.\n",
    "\n",
    "## Multiple files\n",
    "\n",
    "In real research design, you usually don't have only one file to convert, but a lot of them. As an analyst, your task should always be to find a cost effective solution to get these data converted in short time and in the desired format. In this case, this solution is called **for loop**.\n",
    "\n",
    "### What is a for loop?\n",
    "\n",
    "A for loop is a way to apply a same operation or a same set of operations to a defined number of data one by one automatically. In Linux, we are used to use the terminal for a lot of different task, and also in order to perform for loops. This is possible because the terminal gives you an access to the underlying programs saved in the kernel of Linux operating system, and one of the program enabling you to do for loops which is directly bound to your command line terminal is called 'shell'. You have different shell, but let us focuse on the shell that you have on your usb-stick which is 'bash'. This shell (as well as other ones) enables you to perform a for loop, which usually take the following expressions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a variable in my data; do an action with a program on this variable; done i.e. close my for statement and, therefore, my loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let us see what is happening here: \n",
    "\n",
    "  1. a for loop always begins with a 'for' statement, which ends with a semicolon (;);\n",
    "  2. in the for statement, you always define a variable related to the data on which you want to do something;\n",
    "  2. after the semicolon closing the for statement, you always have a 'do' statement which opens the part of the loop in which you are using a program to do something on the defined variable;\n",
    "  3. you always close the do statement with a semicolon (;);\n",
    "  4. you have to close the loop with a 'done' statement in order for the loop to stop and not run again\n",
    "  \n",
    "Let us translate that into a practical example. Let us take the data that we have in our folder ... and construct a loop to convert them into * .txt data: \n",
    "\n",
    "  1. first, cd (change directory) into our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. second open the for loop and define a variable 'i' which is related to all our doc document in this folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in *.doc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. third, convert these doc data to txt data with LibreOffice headless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do !soffice --headless --convert-to txt:Text \"$i\"; # notice the wording of the variable i with '$' for 'variable' and the \"\" to protect it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  4. fourth, close the loop with the done statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together, you will have the following for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !for i in *.doc; do soffice --headless --convert-to txt:Text \"$i\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "\n",
    "Do a for loop to convert sandwiche pdf data into txt data.\n",
    "\n",
    "## Basic scripts\n",
    "\n",
    "Scripts are programs writen in a text editor that enables you to automate the operations on your data, while at the same time keeping the code you have used in order to make your program, which enables you to reuse your program or modify it when you do similar tasks. Scripts work the same as simple lines that you type in your terminal. You can see scripts as a collection of lines that you would otherwise type in your terminal. \n",
    "\n",
    "## Example\n",
    "\n",
    "Let us take your example above of converting a folder of doc data. Often, you don't want to loose the original doc data, and you want to separate them from your converted txt data. To do this, you would do the following: \n",
    "\n",
    "  1. make a directory with your doc data;\n",
    "  2. do the conversion of your doc data into txt data;\n",
    "  3. make a directory for your txt data;\n",
    "  4. save your txt data into the txt directory\n",
    "  \n",
    "A script enables you to automate these four steps and to do them one after one. Let us write such a script. Open a text editor, and write first the command to make a directory for our doc data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir docfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us reuse our for loop to convert our doc data into txt data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !for i in *.doc; do soffice --headless --convert-to txt:Text \"$i\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move your doc data to your docfolder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mv *.doc docfolger # the star means 'take all doc data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a directory for your txt data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir txtfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, move your txt data to your txtfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mv *.txt txtfolder # the star means 'take all txt data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your script should now look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir docfolder\n",
    "# !for i in *.doc; do soffice --headless --convert-to txt:Text \"$i\"; done\n",
    "# mv *.doc docfolder\n",
    "# mkdir txtfolder\n",
    "# mv *.txt txtfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have the content of your script, but this is not a script at the moment, this is just a text file with some command that you would like to input in the shell. To make it a script, you have to write at the top of the file the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/sh # you could also type #!/bin/bash -- sh ensure that your script works for sh and bash shells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this line at the top of your script, you make it recognized by your shell. The last step consists in making this script executable. For this, you have first to save your script as a file 'myscript.sh'. Then, you open a terminal where you have your script and you type the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo chmod +x myscript.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your completed executable script should look like this now: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "# mkdir docfolder\n",
    "# !for i in *.doc; do soffice --headless --convert-to txt:Text \"$i\"; done\n",
    "# mv *.doc docfolder\n",
    "# mkdir txtfolder\n",
    "# mv *.txt txtfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now execute you script with the following command in the folder where you have your doc files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#./myscript.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "\n",
    "Make a script to convert the pdf data in your folder. Pay attention: you have to make distinct folder for the pdf data and the resulting txt data in order to keep doc, pdf data and their corresponding results separated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step -- preprocessing your data\n",
    "\n",
    "In this lecture, you have learned the very first steps of a more general workflow tailored to preprocess your data, and you have begung with basic tasks -- converting data, make simple script to separate the original data from the converted ones. In the next lecture, we cover more advanced methods to preprocess your data based on what we have learn in this lecture. We will use low level programming utilities from the Linux kernel in order to parse our data the way we want to get best results our of our modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script rename files\n",
    "# for i in *.txt; do awk -F, 'NR==1{print $4}' \"$i\" >> date; done #save 4.th col of first line to date file\n",
    "# sed -e 's/^ //' date | awk -F. ' {print $3\"-\"$2\"-\"$1} ' > date2 #reformate dates\n",
    "# ls *.txt > new # save all filename of txt files to new file\n",
    "# sed -i -e 's/^/mv /' new #write mv at the begining of each line\n",
    "# paste -d' ' new date2 > newdate # paste new and date2\n",
    "# ls *.txt > new2 # new date file\n",
    "# paste -d'-' newdate new2 > final #paste filename to new named file\n",
    "# rename final to final.sh and write the #!bin/sh as the first line of the file; make it executable and run it on the data to change filenames "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
