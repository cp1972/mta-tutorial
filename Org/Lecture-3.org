** Data driven preprocessing
   :PROPERTIES:
   :CUSTOM_ID: data-driven-preprocessing
   :END:

In this lecture, we are showing how you can process your text data, and
how you can parse them in order to have the best input for topic
modelling. As you will learn, you have automatic ways to do this
provided by some low level programming utilities which are -- at least
for the major part of them -- natively implemented in the linux
ecosystem and, therefore, are available directly out of your usb-stick.

Even if these utilities are useful, it is rarely the case that they do
all the job for you, so that some handwork might be necessary in case of
texts that are difficult to parse. Take these tools as a way to speed up
your work on the preprocessing of texts, nothing more (but also nothing
less).

** Basics
   :PROPERTIES:
   :CUSTOM_ID: basics
   :END:

Software for data science like the MTA software that we will use in our
lecture mostly work on the basis of simple text files (* .txt data),
which are light-weight and which you can modify in several ways. The
first challenge that you meet when you get some text data is then to
convert them into * .txt data. You can get you data in the following
formats:

- *image data and * .pdf image-data*: in this case, you have to ocerise
  your data by using an ocr which extracts the text out of the data. In
  the Linux ecosystem, you have a very powerful tool to do that which is
  called tesseract-ocr; using your terminal in Linux, you can easily
  install tesseract and its languages files (for the ocerisation in
  several languages) with the following command (cf. our lecture 2):

sudo apt-get install tesseract-ocr tesseract-ocr-all

After that, you can use tesseract-ocr to ocerise your data -- do pay
attention that you need to write a script for tesseract-ocr to work as
you would like (beyond of this tutorial), as f.ex. to ocerise texts in
several languages at once, or to ocerise texts printed in several
columns.

- *sandwich pdf data*: these are a specific case of pdf data which you
  can extract the text by copy/paste from; I don't recommand this,
  because you would also copy non visible elements from the pdf data
  that you would have to hunt down and delete afterwards. Instead, you
  can use a powerful utility called pdftotext to extract the text out of
  these data. You can install this software, which is part of the
  package poppler-utils, using the command line like this:

sudo apt-get install poppler-utils

Let us take a sandwich pdf data like SandwichPDF.pdf, and let us convert
it into txt:

#+BEGIN_SRC python
    #!pdftotext SandwichPDF.pdf # will save the data as SandwichPDF.txt
    # pdftotext SandwichPDF.pdf mytext.txt -- would save the data SandwichPDF.pdf as mytext.txt
#+END_SRC

As you can see in the resulting data, we have made out of this sandwich
pdf is a text data without layout -- and I recommend to do it like this,
because here we have a text on several columns. If you would like to
retain the layout, you could do:

#+BEGIN_SRC python
    #!pdftotext -layout SandwichPDF.pdf
#+END_SRC

You would get a text data preserving (more or less) the layout of the
sandwich pdf -- but you would get problems major difficulties with your
analysis. The reason of that is the following. Let us see a sample of
the resulting text data with the layout:

#+BEGIN_EXAMPLE
          D     ietrich Bonhoeffer ist umstritten.
                Dieses Phänomen zieht sich als roter
          Faden durch Leben und Rezeption des
                                                          von akademischem, sondern auch von
                                                          populärem Interesse.
                                                              Dass Rezeption immer auch Deutung
          Pfarrers, Theologen und Widerständlers.         im Sinne je eigener Auffassungen bis hin   <---- One line == one sentence
          Man kann hier nicht nur an die Entfernung       zur Aneignung bedeuten kann, ist eine
          Bonhoeffers aus dem Lehrkörper der Theo-        Binsenweisheit. Der amerikanische The-  <---- Next difficulty: dash to cut lines will remain
          logischen Fakultät der Berliner Universität,    ologe Stephen R. Haynes hat in seinem
          sondern auch an die problematische Stel-        sehr lesenswerten Buch The Bonhoeffer
          lung im Umfeld der Bekennenden Kirche,          Phenomenon. Portraits of a Protestant Saint
          die Beurteilung des Widerstands im Kon-         gezeigt, in welchem Maße die globale Re-
          text der westdeutschen Nachkriegsgerichts-      zeption Bonhoeffers Elemente klassischer
          barkeit, die umstandslose Vereinnahmung         Hagiografien aufnimmt, warum Bonhoef-
          im Zusammenhang der offiziellen Theolo-         fers Biografie für diese Art der Deutung
          gie der DDR oder den Streit um die liberale     offen ist und welche Chancen und Ge-
          und konservative Deutung in den 1980er-         fahren damit verbunden sind. Zentral ist
          und 1990er-Jahren des 20. Jahrhunderts          der religiös motivierte, entschiedene, bis
          denken.                                         zum Verlust des eigenen Lebens gehende
              Auch der Ansatz von Eric Metaxas,           Einsatz für etwas, das als richtig erkannt
          der Bonhoeffer als Paradigma des kon-           worden ist und – wie im Fall des Wider-
          servativen Evangelikalen zu skizzieren          stands gegen den Nationalsozialismus –
          sucht, ist nicht ganz ohne Vorbilder, hat-      auch allgemein als richtig anerkannt wird.
          te doch Georg Huntemann schon in den            Bedeutsam ist weiterhin der Kontrast zwi-
          1990er-Jahren den „anderen Bonhoeffer“          schen glücklicher Kindheit, erfolgreicher
          verkündet.                                      Jugend und dem konsequenten Dasein als
              Was also ist neu an der Diskussion,         Märtyrer und Zeuge. Zentral ist aber auch
          wer war er wirklich, und was lässt sich von     die Fragmentarität und damit Interpreta-
          ihm für die Gegenwart lernen? Um diese          tionsoffenheit des hinterlassenen Werks.
          Fragen beantworten zu können, lohnt –               Die Chance solcher Deutung liegt in
          gerade angesichts des 75. Jahrestags seiner     der religiösen und moralischen Orientie-
          staatlich angeordneten Ermordung – ein          rungsfunktion, die – weit über den akade-
          Blick auf die Eigenart gegenwärtiger Bon-       mischen Kontext hinaus – gesellschaftlich
          hoeffer-Rezeption und zentrale Aspekte
          seiner theologischen Biografie.                         Gefängniszelle in Berlin-Tegel,
              1. Der „protestantische Heilige“ und sei-      in der Bonhoeffer von 1943 bis 1944
          ne gegenwärtige Rezeption: Es ist nicht zu                              inhaftiert war.
#+END_EXAMPLE

If you pass this text to a learning program, this program will read the
data line by line, and it will interpret these lines as sentences on
which it will compute a model for you. This is clearly something that we
don't want here, because we would have sentences which do not reflect
the content of our text. Therefore, do not use the layout option of
pdftotext.

We know how to deal with pdf data as image or as sandwich pdf. But we
have other types of data, as for example:

- *doc(x)* data;
- *rtf* data;
- *odt(s)* data;
- *htm(l)* data;
- *x(h)tml* data.

In order to convert such data, we can use the LibreOffice --headless
flag, like this at the example of the CP-Abstracts.doc data:

#+BEGIN_SRC python
    #!soffice --headless --convert-to txt:Text CP-Abstracts.doc  #<-- replace .doc with .rtf or .odt or .html etc for corresponding files
#+END_SRC

With these utilities, you can easily achieve the conversion of a lot of
different formats into the * .txt format.

** Multiple files
   :PROPERTIES:
   :CUSTOM_ID: multiple-files
   :END:

In real research design, you usually don't have only one file to
convert, but a lot of them. As an analyst, your task should always be to
find a cost effective solution to get these data converted in short time
and in the desired format. In this case, this solution is called *for
loop*.

*** What is a for loop?
    :PROPERTIES:
    :CUSTOM_ID: what-is-a-for-loop
    :END:

A for loop is a way to apply a same operation or a same set of
operations to a defined number of data one by one automatically. In
Linux, we are used to use the terminal for a lot of different task, and
also in order to perform for loops. This is possible because the
terminal gives you an access to the underlying programs saved in the
kernel of Linux operating system, and one of the program enabling you to
do for loops which is directly bound to your command line terminal is
called 'shell'. You have different shell, but let us focus on the shell
that you have on your usb-stick which is 'bash'. This shell (as well as
other ones) enables you to perform a for loop, which usually take the
following expressions:

#+BEGIN_SRC python
    # for a variable in my data; do an action with a program on this variable; done i.e. close my for statement and, therefore, my loop
#+END_SRC

So let us see what is happening here:

1. a for loop always begins with a 'for' statement, which ends with a
   semicolon (;);
2. in the for statement, you always define a variable related to the
   data on which you want to do something;
3. after the semicolon closing the for statement, you always have a 'do'
   statement which opens the part of the loop in which you are using a
   program to do something on the defined variable;
4. you always close the do statement with a semicolon (;);
5. you have to close the loop with a 'done' statement in order for the
   loop to stop and not run again

Let us translate that into a practical example. Let us take the data
that we have in our folder ... and construct a loop to convert them into
* .txt data:

1. first, cd (change directory) into our folder:

#+BEGIN_SRC python
    # cd folder
#+END_SRC

2. second open the for loop and define a variable 'i' which is related
   to all our doc document in this folder:

#+BEGIN_SRC python
    # for i in *.doc;
#+END_SRC

3. third, convert these doc data to txt data with LibreOffice headless:

#+BEGIN_SRC python
    # do !soffice --headless --convert-to txt:Text "$i"; # notice the wording of the variable i with '$' for 'variable' and the "" to protect it
#+END_SRC

4. fourth, close the loop with the done statement

#+BEGIN_SRC python
    # done
#+END_SRC

All together, you will have the following for loop:

#+BEGIN_SRC python
    # !for i in *.doc; do soffice --headless --convert-to txt:Text "$i"; done
#+END_SRC

** Your turn
   :PROPERTIES:
   :CUSTOM_ID: your-turn
   :END:

Do a for loop to convert sandwich pdf data into txt data.

** Basic scripts
   :PROPERTIES:
   :CUSTOM_ID: basic-scripts
   :END:

Scripts are programs written in a text editor that enables you to
automate the operations on your data, while at the same time keeping the
code you have used in order to make your program, which enables you to
reuse your program or modify it when you do similar tasks. Scripts work
the same as simple lines that you type in your terminal. You can see
scripts as a collection of lines that you would otherwise type in your
terminal.

** Example
   :PROPERTIES:
   :CUSTOM_ID: example
   :END:

Let us take your example above of converting a folder of doc data.
Often, you don't want to loose the original doc data, and you want to
separate them from your converted txt data. To do this, you would do the
following:

1. make a directory with your doc data;
2. do the conversion of your doc data into txt data;
3. make a directory for your txt data;
4. save your txt data into the txt directory

A script enables you to automate these four steps and to do them one
after one. Let us write such a script. Open a text editor, and write
first the command to make a directory for our doc data:

#+BEGIN_SRC python
    # mkdir docfolder
#+END_SRC

Now let us reuse our for loop to convert our doc data into txt data:

#+BEGIN_SRC python
    # !for i in *.doc; do soffice --headless --convert-to txt:Text "$i"; done
#+END_SRC

Move your doc data to your docfolder:

#+BEGIN_SRC python
    # mv *.doc docfolder # the star means 'take all doc data'
#+END_SRC

Make a directory for your txt data:

#+BEGIN_SRC python
    # mkdir txtfolder
#+END_SRC

Finally, move your txt data to your txtfolder

#+BEGIN_SRC python
    # mv *.txt txtfolder # the star means 'take all txt data'
#+END_SRC

Your script should now look like this:

#+BEGIN_SRC python
    # mkdir docfolder
    # !for i in *.doc; do soffice --headless --convert-to txt:Text "$i"; done
    # mv *.doc docfolder
    # mkdir txtfolder
    # mv *.txt txtfolder
#+END_SRC

You have the content of your script, but this is not a script at the
moment, this is just a text file with some command that you would like
to input in the shell. To make it a script, you have to write at the top
of the file the following:

#+BEGIN_SRC python
    #!/bin/sh # you could also type #!/bin/bash -- sh ensure that your script works for sh and bash shells
#+END_SRC

With this line at the top of your script, you make it recognized by your
shell. The last step consists in making this script executable. For
this, you have first to save your script as a file 'myscript.sh'. Then,
you open a terminal where you have your script and you type the
following:

#+BEGIN_SRC python
    # sudo chmod +x myscript.sh
#+END_SRC

Your completed executable script should now look like this:

#+BEGIN_SRC python
    #!/bin/sh
    # mkdir docfolder
    # !for i in *.doc; do soffice --headless --convert-to txt:Text "$i"; done
    # mv *.doc docfolder
    # mkdir txtfolder
    # mv *.txt txtfolder
#+END_SRC

Now execute you script with the following command in the folder where
you have your doc files:

#+BEGIN_SRC python
    #./myscript.sh
#+END_SRC

** Your turn
   :PROPERTIES:
   :CUSTOM_ID: your-turn-1
   :END:

Make a script to convert the pdf data in your folder. Pay attention: you
have to make distinct folder for the pdf data and the resulting txt data
in order to keep doc, pdf data and their corresponding results
separated.

** Next step -- preprocessing your data
   :PROPERTIES:
   :CUSTOM_ID: next-step-preprocessing-your-data
   :END:

In this lecture, you have learned the very first steps of a more general
workflow tailored to preprocess your data, and you have begun with basic
tasks -- converting data, make simple script to separate the original
data from the converted ones. In the next lecture, we cover more
advanced methods to preprocess your data based on what we have learn in
this lecture. We will use low level programming utilities from the Linux
kernel in order to parse our data the way we want to get best results
our of our modeling.

#+BEGIN_SRC python
    #script rename files
    # for i in *.txt; do awk -F, 'NR==1{print $4}' "$i" >> date; done #save 4.th col of first line to date file
    # sed -e 's/^ //' date | awk -F. ' {print $3"-"$2"-"$1} ' > date2 #reformate dates
    # ls *.txt > new # save all filename of txt files to new file
    # sed -i -e 's/^/mv /' new #write mv at the begining of each line
    # paste -d' ' new date2 > newdate # paste new and date2
    # ls *.txt > new2 # new date file
    # paste -d'-' newdate new2 > final #paste filename to new named file
    # rename final to final.sh and write the #!bin/sh as the first line of the file; make it executable and run it on the data to change filenames 
#+END_SRC
