* MTA als Software für die TM-Analyse

TM-Analysen können mit unterschiedlichen Software konzipiert werden, wie etwa:

- [[https://mimno.github.io/Mallet/topics.html][Mallet]]
- [[https://cran.r-project.org/][R]] vom CRAN-Projekt
- KI-Agenten
- [[https://scikit-learn.org/stable/][Scikit-learn]] mit der Programmiersprache Python

Verschiedene Techniken der Analysen von qualitativen Daten wurden in Bash mit Mallet getestet, dann in R systematisiert und in Python mit Scikit-learn weiter entwickelt. Der Grund für die Auswahl von Python und Scikit-learn als Grundlage von MTA ergibt sich daraus, dass es in diesem Zusammenhang leichter war, verschiedene Algorithmen zur TM-Analyse miteinander zu verbinden, und weil Python erlaubt hat, MTA besser je nach den unterschiedlichen Bedürfnissen von Testern zu personalisieren. Ein Vorteil ist auch, das MTA auf MacOS, Windows und Unixes Systeme läuft.

KI-Agenten wurden nicht wirklich herangezogen, weil das Verfahren nicht dazu führen sollte, vollständige automatische Systeme zu entwickeln -- das hat Vorteile aber auch Nachteile (vgl. unsere zweite Sitzung), die wir vermeiden wollten.

* Python installieren

Um MTA verwenden zu können, muss Python in der dritten Version (python3.xx.xx) installiert werden. Unixes Systeme wie etwa Linux Distributionen kommen mit Python vorinstalliert. Für Windows und MacOS gibt es verschiedene Installationsmöglichkeiten:

- Windows: Python kann unterschiedlich installiert werden:
  - über das Microsoft-Store -- dies ist der leichteste Weg, eine Version von Python zu installieren; erforderlich ist die Installation von der App Microsoft Store, dann kann eine Python Version gesucht werden (etwa Python 3.11) und mit 'Get' installiert werden;
  - über die Anwendung Anaconda;
  - über Windows WSL2 -- mit WSL2 kann unter Windows ein virtuelles Linux-System installiert werden, das eine Version von Python enthält

- MacOS: Python kann mit Homebrew installiert werden; die Anwendung Anaconda für MacOS erlaubt ebenfalls die Installation von Python.

Zusätzlich zu dieser Installation müssen Windows-Benutzer dafür sorgen, dass ihr Windows die UTF-8 Codierung unterstützt. Dafür muss in Windows die folgende Änderung vorgenommen werden:

- Unter Einstellungen > Zeit und Sprache > Region > Administrative Spracheinstellungen > Systemgebietsschema gehen, und dann die Option "Beta: Unicode UTF-8 verwenden für globale Sprachunterstützung" aktivierten. Starten Sie den PC neu, damit die Änderung wirksam wird.

Wenn Python installiert wurde, müssen Bibliotheken installiert, die MTA braucht. Die Github-Seite von MTA git Hinweise darauf, welche Bibliotheken installiert werden müssen. Eine Bibliothek kann dann wie folgt installiert werden:

#+begin_src shell :results drawer
pip3 install matplotlib
#+end_src

Damit sollte alles vorhanden sein, um MTA zu benutzen.

* 3 Stufen von MTA

MTA funktioniert nach drei Stufen:

- Stufe I: die Vorbereitung der Dokumente für die Analyse -- Vorstellung in diesem Dokument
- Stufe II: die TM-Analyse selbst -- Vorstellung in der Sitzung
- Stufe III: weitere Analysen auf der Grundlage der TM-Analyse -- Vorstellung in der Sitzung

* Stufe I. Vorbereitung der Dokumente

Diese Stufe ist die wichtigste und für Personen, die mit Rechnertechniken nicht gut umgehen können, häufig die schwierigste Stufe. Diese Stufe wird zum Teil außerhalb von MTA durchgeführt, damit die Dokumente, die analysiert werden, vom Benutzer nach seinem/ihrem Bedürfnissen vorbereitet werden.

** Vorbereitung außerhalb von MTA

Eine solche Vorbereitung außerhalb von MTA bedeutet:

- die Dateien müssen in *.txt Dateien im Format UTF-8 umgewandelt werden -- hier stellt sich die Frage, wie *.doc(x) oder etwa *.pdf Dokumente in *.txt Dokumente umgewandelt werden können, welche Anwendungen dafür gebraucht werden; wichtig insbesondere für Windows Benutzer ist die Umwandlung in die UTF-8 Codierung, die von MTA anerkannt wird; die spezifische Windows Codierung wird nicht unterstützt (MTA wird nicht funktionieren).
- eine Liste von Wörtern muss vorbereitet werden, die man in die Analyse nicht mit aufnehmen möchte (Rausch vermeiden) -- diese Liste enthält ein Wort je Zeile des Dokuments und kann personalisiert werden

** Beispiele

Hiermit einige Beispiele zur Umwandlung von verschiedenen Dateien:

  Für PDF-Dateien:

  #+begin_src shell :var convpath="/home/cpsoz/Github/mta-tutorial/DOC-Convert" :results drawer
  pdftotext $convpath/SandwichPDF.pdf
  #+end_src

  Für DOC-Dateien -- und auch DOCX, RTF, HTML, ODT usw.

  #+begin_src shell :var convpath="/home/cpsoz/Github/mta-tutorial/DOC-Convert" :results drawer
  soffice --headless --convert-to txt:Text $convpath/CP-Abstracts.doc
  #+end_src

Hiermit ein Beispiel für eine Stopwords-Liste

  #+begin_src shell :results drawer :var stopath="/home/cpsoz/Github/mta-tutorial/Stopwords"
  cat $stopath/de.txt | head
  #+end_src

** Vorbereitung innerhalb von MTA

Hat man seine Dokumente konvertiert und eine Liste von Wörtern vorbereitet, die in der Analyse nicht berücksichtigt werden, dann kann man mit MTA starten und die weitere Vorbereitung der Dokumente für die Analyse durchführen.

*** Dokumente auswählen

Hier muss man auf das Folgende aufmerksam sein:

- Wo sind meine Dokumente?: MTA sucht Dokumente nach dem Pfad zu den Dokumenten, den der Benutzer angibt; es ist ein vollständiger Pfad, deshalb ist es für den Benutzer wichtig, es zu erkennen, wo sich seine Dokumente auf seinem Rechner befinden;
- Dokumente in Einzelordner ohne Unterordner: die Dokumente, die analysiert werden, müssen in einem Ordner gespeichert werden, der keine Subordner enthält;
- Alle Dokumente nehmen: in MTA sagen wir mit einem Sternchen am Ende vom Pfad, dass wir alle Dokumente im angegebenen Ordner mit in die Analyse aufnehmen möchten;

Wenn dies gemacht wurde, ergibt MTA ein Beispiel der max. drei ersten Dokumente im Ordner, in dem sich die Dokumente befinden, und MTA fragt, ob diese Dokumente die richtigen sind. Der Benutzer bestätigt dies mit 'y' oder 'yes' für ja (bzw. 'n' oder 'no' für nein).

#+begin_src shell :results drawer :var mtapath="/home/cpsoz/Github/mta-app"
  sed -n -e 158p -e 161p -e 166p $mtapath/MTA.py
#+end_src

*** Stopwords-Liste angeben

Wenn die richtigen Dokumente angegeben werden, muss anschließend eine Stopwords-Liste angegeben werden; hier auch muss der vollständigen Pfad zu dieser Liste angegeben werden, ansonsten wird MTA nochmal fragen, wo sich die Liste befindet.

#+begin_src shell :results drawer :var mtapath="/home/cpsoz/Github/mta-app"
  sed -n 184p $mtapath/MTA.py
#+end_src

*** Minimale Anzahl an Buchstaben zur Aufnahme von Begriffen in den Dokumenten

Wir haben jetzt unsere Dokumente innerhalb von MTA, und wir haben eine Stopwords-Liste geladen. Wir müssen entscheiden, ob MTA alle Begriffe in den Dokumenten berücksichtigt, oder ob MTA nur bestimmte Begriffe berücksichtigt.

Dies nennt man eine "Bag of Words" (BOW) Methode, damit MTA wie KI-Agenten verwenden. Die Überlegung, die damit verbunden ist, ist die Folgende: Wir nehmen Begriffe in Dokumente auf, um zu wissen, wie sie miteinander in Sätzen und Absätzen von Dokumenten verbunden sind bzw. ob sie häufig oder weniger häufig zusammen auftauchen.

Es ist nicht sinnvoll, alle Begriffe zu berücksichtigen, weil nicht alle Wörter inhaltlich relevant für je nachdem sind, was wir für eine Fragestellung formuliert haben. Dies sehen wir schon mit der Verwendung von einer Stopwords-Liste. Diese Selektion von Begriffen können wir noch näher bestimmen, wenn wir MTA sagen, dass nur Wörter ab 4 oder 5 oder 6 usw. in der Analyse berücksichtigt werden müssen.

Entsprechend sagt man MTA, dass er Begriffe, die weniger als diese Anzahl an Buchstaben enthalten, nicht berücksichtigen muss.

#+begin_src shell :results drawer :var mtapath="/home/cpsoz/Github/mta-app"
  sed -n 194p $mtapath/MTA.py
#+end_src

*** Fine tuning

Wir haben die Wörterlänge für die Berechnung der Verbindungen zwischen Wörtern angepasst. Jetzt können wir die Modellierung bestimmen. Dafür benutzen wir zwei Parametern, um Wörter aus der Analyse auszuschließen. Es sind zwei Arten von Wörtern:

- Wörter, die sehr häufig auftauchen: weil diese Wörter sehr häufig auftauchen, werden sie die Analyse verzerren, weil sie den Eindruck geben, dass sie sehr wichtig sind; das ist nicht unbedingt der Fall, deshalb kann man sagen, dass wir solche Wörter nicht in der Analyse nehmen;
- Wörter, die sehr selten sind: aus dem selben Grund wie hier oben können wir solche Wörter aus der Analyse ausschließen, weil wenn sie sehr selten auftauchen, sind sie für das gesamte Verständnis von den Texten nicht wichtig.

Damit normalisieren wir die Verteilung der Wörter in den Dokumenten, und diese Normalisierung ist deshalb vorteilhaft, weil sie den Wortschatz in den Dokument nach einer Gauss-Kurve organisiert. Wir haben einerseits eine Minderheit von Wörtern, die weniger häufig bzw. sehr häufig auftauchen in den Dokumenten, ohne das wir extrem seltene oder extrem häufig auftauchende Wörter mitnehmen. Andererseits haben wir eine Mehrheit von Wörter, die mehr oder weniger oft in den Dokumenten auftauchen.

#+begin_src shell :results drawer :var mtapath="/home/cpsoz/Github/mta-app"
  sed -n 317,321p $mtapath/MTA.py
#+end_src

*** Schriftart und Sprache

Die interne Vorbereitung der Dokumente ist erfolgt. MTA gibt noch die Möglichkeit, die Schriftart und die Sprache für die Abbildungen auszuwählen, die wir in der Analyse generieren. Die Schriftarten müssen zuerst auf dem Rechner sein, damit sie MTA verwenden kann.

#+begin_src shell :results drawer :var mtapath="/home/cpsoz/Github/mta-app"
  sed -n 385,389p $mtapath/MTA.py
#+end_src

#+begin_src shell :results drawer :var mtapath="/home/cpsoz/Github/mta-app"
  sed -n 393,403p $mtapath/MTA.py
#+end_src

Damit können wir in die TM-Analyse starten.

* Nächster Schritt

Im nächsten Schritt beschäftigen wir uns mit der [[./Lecture-4-de.org][Modellierung von Daten mit MTA]].
