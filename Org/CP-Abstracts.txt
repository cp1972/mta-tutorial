State of the art
Since the 1950s, language models have primarily been developed to solve the specific problem of translating a language into another language (Hutchins 1995). Until the 1980s, however, such translation experiments proved inconclusive. The computer could translate a limited amount of text using statistical procedures to match words in sentences, it could not handle long sequences of words and often required human intervention (Pierce und Carroll 1966; Zong und Krishnamachari 2022). Technical progress, especially the empowerment of computing capacity (CPU and GPU) and random access memory (RAM), made it possible to store more data and to broaden the scope of statistical operations, leading to the concept of Recurrent Neural Network (RNN) in the mid-1980s. This concept describes a method to address relationships between words in language based on models of the relationships between neurons in the human brain. The RNN method allowed to establish more correspondences between words of the same sequence (deep learning assessment) and operated on more extensive sequences of words. This model has led to more sophisticated language models (e.g. bidirectional recurrent neural networks and others, see Hochreiter und Schmidhuber 1997) but remained costly regarding computing resources. At the beginning of 2017, GPT models were developed to solve this problem by using transformers to construct word vectors for each word in a sequence of words, which have been called "attention vectors", instead of one vector for one sequence of words. Such vectors allow each of these words to be related to others that most likely occur with one given word in a given language based on a given corpus of primarily textual data. GPT models are, thus, on the one hand, an extension of deep neural language models. On the other hand, they have the particularity of being able to predict the probability of a word B appearing after a word A based on the restricted context of words regularly related to the word A while – in subsequent versions of the transformers – being able to reuse the result of this prediction to refine future predictions (see also Devlin u. a. 2019). This allows the GPT models to be potentially applied to any extensive data collection without correspondingly altering the quality of the predictions too fast.
Compared to preexisting language models, recent GPT models like GPT-3 are general-purpose models. They can address a vast spectrum of problems (from simple question-answer problems of general knowledge to technical questions of scientific knowledge in medicine; see Zong und Krishnamachari 2022), eventually supporting their implementation in several societal fields of activity. In this regard, they differ from more specific language models used to classify documents or to reconstruct themes or semantic chains of words structuring these documents, such as, for example, the language models used in the framework of classical NLP tasks like named entity recognition (NER), sentiment analysis or topic modelling (for an overview, see Papilloud und Hinneburg 2018). First public experiments with GPT models have quickly found exposure in daily newspapers and affiliated narratives, mainly around the beta version of one GPT-3 model that OpenAI published on the Internet by the fall of 2021 (cf. https://www.openai.com). OpenAI is a data science firm specialising in developing and operating algorithms or intelligent robots which released a chatbot prototype named ChatGPT. ChatGPT uses a GPT language model trained based on two reinforcement-learning procedures. The model behaves like a (quasi)self-dynamic and (quasi)self-acting software that gradually learns relations between textual elements to maximise positive as well as negative predictions regarding future relations between these elements. It has been trained on five billion textual data from the Internet, including books, Wikipedia, social media conversations, scholarly publications ({https://www.scientificamerican.com/article/we-asked-gpt-3-to-write-an-academic-paper-about-itself-mdash-then-we-tried-to-get-it-published/) and websites. The model can process long text sequences and autonomously generate human-like texts responding to a natural language input (questions, statements or commands) given at a command line prompt (cf. https://dev.to/abbhiishek/chatgpt-the-ultimate-tool-for-natural-language-processing-and-text-generation-40ag). The generated text can be different, from cooking receipts to complex articles virtually able to meet scientific standards (cf. https://www.scientificamerican.com/article/we-asked-gpt-3-to-write-an-academic-paper-about-itself-mdash-then-we-tried-to-get-it-published/).
In the scientific community and beyond, GPT models have stimulated debates about the value of knowledge in the interplay between human beings and digital technologies, partly inheriting from the debates about distributed cognition in neuro- and cognitive sciences (Magnus 2007; Kourken und Sutton 2013; Anderson, Sprevak, und Wheeler 2018; Risku und Rogl 2020), as well as from debates about the role of algorithms in support of human decision (Pariser 2012; Anderson 2012; Braverman 2012; Bucher 2018; Lee und Larsen 2019). According to Zhang et al. (2021), transformer-based language models have achieved human-like language understanding abilities and offer an intuitive, natural language-based user interaction method. As AI takes on more responsibilities, the role of humans in knowledge processes will change. However, such language models are not free from different difficulties.
Because they remain primarily based on one-way encoding-decoding transformers and statistical probabilities to predict the following tokens, GPT models tend to fail at simple reversible answers that can be solved by common knowledge. They must also correctly address classification tasks on specific corpus related to more specific themes and containing fewer, i.e. hundreds to thousands of documents (Floridi und Chiriatti 2020). Moreover, GPT-based language models do not involve any regulation policy to prevent the misuse of such models (Dehouche 2021; Brown u. a. 2020). They produce biases related to gender representation, discriminating against women in favour of men's representation (Lucy und Bamman 2021; Shihadeh u. a. 2022); they also produce racial and religious biases, discriminating against people based on their skin colour or beliefs and favouring white christian people like f.ex. in usages of GPT models in medicine related to pain management and the treatment of pain (Logé u. a. 2021). Moreover, while language models are constantly developing, such models require considerable resources to be consumed, leading to serious environmental concerns (Zong und Krishnamachari 2022).
Even if this literature critically addresses the development and some applications of GPT language models in everyday life, it does not specifically address the individual's ability to balance knowledge-creating and knowledge-applying activities, which represents a key challenge for such hybrid knowledge processes at the intersection of humans and model languages. Our project fills this gap by investigating how such individuals' ambidexterity and development would support knowledge-based competencies at the interface of human beings and language models. Individual ambidexterity describes the extent to which individuals can pursue explorative and exploitative activities within their work roles (Kauppila & Tempelaar, 2016; Bledow et al., 2009). Thereby, explorative activities comprise searching for new opportunities, experimenting, and learning, whereas exploitative activities include refining, implementing, or carrying out routines (Mom et al., 2009; March, 1991). As explorative and exploitative activities are based on different cognitive demands (Bidmon & Boe-Lillegraven, 2020), it is assumed that individuals cannot engage in both activities and need to switch continuously depending on situational work requirements (Gupta et al., 2006; Bledow et al., 2009; Tempelaar & Rosenkranz, 2019). Against the background of earlier experimental research on using GPT langauge models in teaching mathematics (Wang, Liu, and Shi 2017; Wu u. a. 2020; Zhang u. a. 2020), this project designs an experimental study to determine the impact of knowledge inflow by contemporary transformer-based language models (such as ChatGPT) on individual ambidexterity (knowledge exploitation, knowledge exploration or integration of both).
