{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelling Qualitative Data -- Overview\n",
    "\n",
    " 1. Goal: learning a general workflow that you can easily implement to modelling qualitative data\n",
    " 2. Tools: \n",
    "     - mainstream Linux operating system \n",
    "     - dataset consisting in various text based data\n",
    "     - low level native Unix programs to preprocess your data\n",
    "     - python programs to do your analysis\n",
    "     - python programs to layout your results\n",
    "     - python programs to make presentations of your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are qualitative data and how to modelling them\n",
    "\n",
    "1. Qualitative data: mostly text based data of various types (not uniquely, f.ex. also pictures)\n",
    "    - postcards, vignettes, short texts (f.ex. tweets)\n",
    "    - newspapers' articles\n",
    "    - scientific articles\n",
    "    - books\n",
    "    - corpora = collections of text data, i.e. big (qualitative) data\n",
    "\n",
    "2. Modelling techniques: techniques to understand the information content of your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Several modelling techniques -- Exclusively human-centric techniques\n",
    "\n",
    "1. human-centric techniques:\n",
    "   - based on reading the dataset and interpret it\n",
    "   - categorization of the information content in the dataset\n",
    "   - structuration of the categories based on the interpretation of dataset\n",
    "   - result: analysis of this structure = output the hidden/latent structure of the dataset\n",
    "        \n",
    "     * advantages: \n",
    "       - based on the human understanding of texts = better control over the interpretation of texts\n",
    "       - sensible to polysemic meaning of words/texts\n",
    "     * disadvantages:\n",
    "       - difficult to scale results to the total amount of the investigated material -- main results often apply to 10-15% of the investigated material       \n",
    "       - difficult to generalized results out of the given dataset\n",
    "       - difficult to reproduce the results\n",
    "       - difficult to share the results with other researchers\n",
    "       - difficult to generalized the results to other sources/actors where the dataset comes from\n",
    "       - possible interpretation bias\n",
    "       - time consuming --> often limit the scope of data that can be investigated in a given time\n",
    "       - complete quantitative oriented research designs, but not compatible with them = parallel routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Several modelling techniques -- Mostly human-centric techniques\n",
    "\n",
    "2. mostly human-centric techniques, with the help of basic computing:\n",
    "   - based on reading the dataset and interpret it\n",
    "   - categorization of the information content in the dataset -- computer driven\n",
    "   - basic statistics (mostly frequencies of words' occurrences and distribution of words)\n",
    "   - structuration of the categories based on the interpretation of dataset -- computer driven\n",
    "   - basic structuration tools (f.ex. MAXQDA, NLP techniques)\n",
    "   - result: analysis of this structure = output the hidden/latent structure of the dataset\n",
    "   \n",
    "     * advantages: \n",
    "       - based on the human understanding of texts, add computer driven facilities\n",
    "       - sensible to polysemic meaning of words/texts\n",
    "       - better at generalizing the results out of the given dataset than exclusively human-centric techniques\n",
    "       - less time consuming than human-centric techniques\n",
    "     * disadvantages:\n",
    "       - difficult to scale results to the total amount of the investigated material -- main results often apply to 10-15% of the investigated material       \n",
    "       - difficult to reproduce the results\n",
    "       - difficult to share the results with other researchers\n",
    "       - difficult to generalized the results to other sources/actors where the dataset comes from\n",
    "       - possible interpretation bias\n",
    "       - complete quantitative oriented research designs, but not compatible with them = parallel routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Several modelling techniques -- Partly human-centric techniques\n",
    "\n",
    "3. partly human-centric techniques, partly computer driven:\n",
    "   - reading the dataset and processing it is computer driven\n",
    "   - categorization of the information content in the dataset -- computer driven\n",
    "   - advanced analytics using statistic or mathematic modelling methods\n",
    "   - structuration of the categories based on the modelling methods\n",
    "   - advanced structuration tools (f.ex. R, Python)\n",
    "   - result: analysis of this structure = output the hidden/latent structure of the dataset --> rests on human understanding of the results\n",
    "   \n",
    "     * advantages:\n",
    "       - based on the human understanding of texts, add advanced data analytics\n",
    "       - better scaling of the results --> apply to the total amount of the investigated material\n",
    "       - better at generalizing the results out of the given dataset than other human-centric techniques\n",
    "       - less time consuming than other human-centric techniques\n",
    "       - results can easily be reproduced\n",
    "       - results can easily be shared with other researchers\n",
    "       - better at generalizing the results to other sources/actors where the dataset comes from\n",
    "       - better at accumulating further data to enrich the dataset\n",
    "       - better at comparing same kind of data in different languages\n",
    "       - reduce the interpretation bias\n",
    "       - better compatibility with quantitative oriented research designs = converging routes\n",
    "     * disadvantages:\n",
    "       - less sensible to polysemic meaning of words/texts (even in AI framworks)\n",
    "       - knowledge demanding --> skills in programming (which can be time consuming)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Right tools for the right tasks -- Operating systems\n",
    "\n",
    "1. Why Linux?\n",
    "  - opensource operating system -- easy to install and maintain at no economic costs\n",
    "  - take the most out of dated hardware --> reuse your old computers\n",
    "  - portable -- use the OS on a lot of hardware, as well as from simple external drives or USB keys\n",
    "  - mainstream software for all mainstream tasks\n",
    "  - powerfull software for data analytics:\n",
    "    - install R CRAN and related packages \n",
    "    - Python comes natively with the operating system\n",
    "    - benefit from native unix low programming utilities to tailor the dataset\n",
    "    - deliver opensource free software to extend the analytic framework\n",
    "    \n",
    "2. Why not Windows or MacOS (or * BSD)?\n",
    "    - cost of the operating system and the software\n",
    "    - no portability of the software to other hardware -- you have to stick with one given hardware\n",
    "    - Windows: no out-of-the-box tools to tailor the dataset --> limited choice of unix tools compatible with Windows\n",
    "    - MacOS and * BSD flavors: some out-of-the-box tools to tailor the dataset --> not always compatible with same unix tools -- * BSD OS are more involving\n",
    "    - but: you can install R (directly) and Python (with f.ex. Anaconda) for data analytics\n",
    "    - but: you can install opensource free software to extend the analytic framework\n",
    "    \n",
    "Linux is more often used in the context of data analytics because of its practicability and scaling capacity. Disadvantage: coming from Windows or MacOS, there is a learning curve regarding: \n",
    "  - the use of the command line\n",
    "  - the use of equivalent software to the ones you have on Windows/MacOS --> f.ex. LibreOffice instead of Microsoft Office\n",
    "  - in general: changing some of your habits\n",
    "\n",
    "Benefit: gain in autonomy with your research purpose --> you can do and design your work and workflow as you want, i.e. you are not limited by the OS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Right tools for the right tasks -- Software\n",
    "\n",
    "1. Why Python and not R?\n",
    "  - both are excellent software and programming environment with a long history and a great community\n",
    "  - both have a learning curve\n",
    "  - R -- mainly used for statistics\n",
    "  - Python -- more general approach to data science\n",
    "  - R -- you use the flexibility of R libraries\n",
    "  - Python -- you can write your application from scratch\n",
    "  - R -- runs locally\n",
    "  - Python -- better integration with apps and better deployment \n",
    "\n",
    "Python is often the first and evident choice when it comes to machine learning framework design -- easy to find support and material for your work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
